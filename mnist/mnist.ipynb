{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование размерности изображений\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация данных\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем метки в категории\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем последовательную модель\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем уровни сети\n",
    "model.add(Dense(800, input_dim=784, activation=\"relu\", kernel_initializer=\"normal\"))\n",
    "model.add(Dense(10, activation=\"softmax\", kernel_initializer=\"normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Компилируем модель\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                8010      \n",
      "=================================================================\n",
      "Total params: 636,010\n",
      "Trainable params: 636,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/25\n",
      " - 7s - loss: 1.3220 - acc: 0.6916 - val_loss: 0.7795 - val_acc: 0.8502\n",
      "Epoch 2/25\n",
      " - 1s - loss: 0.6730 - acc: 0.8522 - val_loss: 0.5376 - val_acc: 0.8732\n",
      "Epoch 3/25\n",
      " - 1s - loss: 0.5239 - acc: 0.8726 - val_loss: 0.4494 - val_acc: 0.8883\n",
      "Epoch 4/25\n",
      " - 1s - loss: 0.4561 - acc: 0.8836 - val_loss: 0.4033 - val_acc: 0.8976\n",
      "Epoch 5/25\n",
      " - 1s - loss: 0.4161 - acc: 0.8912 - val_loss: 0.3734 - val_acc: 0.9034\n",
      "Epoch 6/25\n",
      " - 1s - loss: 0.3889 - acc: 0.8961 - val_loss: 0.3530 - val_acc: 0.9062\n",
      "Epoch 7/25\n",
      " - 1s - loss: 0.3686 - acc: 0.9008 - val_loss: 0.3370 - val_acc: 0.9103\n",
      "Epoch 8/25\n",
      " - 1s - loss: 0.3528 - acc: 0.9039 - val_loss: 0.3249 - val_acc: 0.9113\n",
      "Epoch 9/25\n",
      " - 1s - loss: 0.3399 - acc: 0.9068 - val_loss: 0.3145 - val_acc: 0.9141\n",
      "Epoch 10/25\n",
      " - 1s - loss: 0.3289 - acc: 0.9095 - val_loss: 0.3061 - val_acc: 0.9165\n",
      "Epoch 11/25\n",
      " - 1s - loss: 0.3194 - acc: 0.9123 - val_loss: 0.2985 - val_acc: 0.9170\n",
      "Epoch 12/25\n",
      " - 1s - loss: 0.3110 - acc: 0.9143 - val_loss: 0.2916 - val_acc: 0.9202\n",
      "Epoch 13/25\n",
      " - 1s - loss: 0.3035 - acc: 0.9163 - val_loss: 0.2855 - val_acc: 0.9214\n",
      "Epoch 14/25\n",
      " - 1s - loss: 0.2967 - acc: 0.9180 - val_loss: 0.2795 - val_acc: 0.9235\n",
      "Epoch 15/25\n",
      " - 1s - loss: 0.2904 - acc: 0.9197 - val_loss: 0.2747 - val_acc: 0.9241\n",
      "Epoch 16/25\n",
      " - 1s - loss: 0.2844 - acc: 0.9214 - val_loss: 0.2702 - val_acc: 0.9264\n",
      "Epoch 17/25\n",
      " - 1s - loss: 0.2792 - acc: 0.9231 - val_loss: 0.2655 - val_acc: 0.9273\n",
      "Epoch 18/25\n",
      " - 1s - loss: 0.2741 - acc: 0.9242 - val_loss: 0.2611 - val_acc: 0.9291\n",
      "Epoch 19/25\n",
      " - 1s - loss: 0.2692 - acc: 0.9257 - val_loss: 0.2572 - val_acc: 0.9300\n",
      "Epoch 20/25\n",
      " - 1s - loss: 0.2646 - acc: 0.9271 - val_loss: 0.2533 - val_acc: 0.9307\n",
      "Epoch 21/25\n",
      " - 1s - loss: 0.2603 - acc: 0.9283 - val_loss: 0.2497 - val_acc: 0.9310\n",
      "Epoch 22/25\n",
      " - 1s - loss: 0.2560 - acc: 0.9296 - val_loss: 0.2464 - val_acc: 0.9319\n",
      "Epoch 23/25\n",
      " - 1s - loss: 0.2521 - acc: 0.9305 - val_loss: 0.2432 - val_acc: 0.9326\n",
      "Epoch 24/25\n",
      " - 1s - loss: 0.2482 - acc: 0.9312 - val_loss: 0.2406 - val_acc: 0.9338\n",
      "Epoch 25/25\n",
      " - 1s - loss: 0.2446 - acc: 0.9324 - val_loss: 0.2366 - val_acc: 0.9342\n",
      "Wall time: 28.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1beaee4d4a8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Обучаем сеть\n",
    "model.fit(X_train, Y_train, batch_size=200, epochs=25, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность работы на тестовых данных: 93.48%\n"
     ]
    }
   ],
   "source": [
    "# Оцениваем качество обучения сети на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23613934565484523, 0.9348]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.asozykin.ru/courses/nnpython-lab1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|epochs|batch_size|input layer|hidden layer|time|loss|acc|\n",
    "|---|---|---|---|---|---|---|\n",
    "|xxx|---|---|---|---|---|---|\n",
    "| 25|200|800|-|colab 32.2 s|0.2342|0.9358|\n",
    "| 25|200|800|-|28.7 s|0.2366|0.9342|\n",
    "| 50|200|800|-|49.7 s|0.1537|0.9589|\n",
    "| 75|200|800|-|1min 7s|0.1116|0.9692|\n",
    "|100|200|800|-|1min 27s|0.0908|0.9734|\n",
    "|125|200|800|-|1min 49s|__0.0809__|__0.9759__|\n",
    "|---|xxx|---|---|---|---|---|\n",
    "| 25|50|800|-|1min 14s|0.0776|0.9768|\n",
    "| 25|100|800|-|39.5 s|0.0760|0.9773|\n",
    "| 25|200|800|-|22.2 s|0.0755|0.9775|\n",
    "| 25|400|800|-|15.3 s|__0.0753__|__0.9778__|\n",
    "|---|---|xxx|---|---|---|---|\n",
    "| 25|200|500|-|21.9 s|0.2447|0.9306|\n",
    "| 25|200|700|-|24.1 s|0.2376|0.9341|\n",
    "| 25|200|900|-|24 s|0.2295|0.9373|\n",
    "| 25|200|1200|-|25.3 s|__0.2189__|__0.9399__|\n",
    "|---|---|---|xxx|---|---|---|\n",
    "| 25|200|800|500|26 s|0.1803|0.9507|\n",
    "| 25|200|800|700|27.9 s|0.1693|0.9530|\n",
    "| 25|200|800|900|28.9 s|0.1615|__0.9562__|\n",
    "| 25|200|800|1200|29.5 s|__0.1591__|0.9548|\n",
    "|---|---|---|---|---|---|---|\n",
    "| 125|400|1200|1200|1min 51s|0.1035|0.9701|\n",
    "| 125|200|1200|1200|2min 53s|0.0809|0.9763|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/125\n",
      " - 2s - loss: 0.9163 - acc: 0.7803 - val_loss: 0.4682 - val_acc: 0.8903\n",
      "Epoch 2/125\n",
      " - 1s - loss: 0.4249 - acc: 0.8918 - val_loss: 0.3469 - val_acc: 0.9107\n",
      "Epoch 3/125\n",
      " - 1s - loss: 0.3441 - acc: 0.9081 - val_loss: 0.3018 - val_acc: 0.9191\n",
      "Epoch 4/125\n",
      " - 1s - loss: 0.3047 - acc: 0.9160 - val_loss: 0.2748 - val_acc: 0.9243\n",
      "Epoch 5/125\n",
      " - 1s - loss: 0.2790 - acc: 0.9235 - val_loss: 0.2566 - val_acc: 0.9297\n",
      "Epoch 6/125\n",
      " - 1s - loss: 0.2602 - acc: 0.9278 - val_loss: 0.2418 - val_acc: 0.9328\n",
      "Epoch 7/125\n",
      " - 1s - loss: 0.2451 - acc: 0.9318 - val_loss: 0.2301 - val_acc: 0.9368\n",
      "Epoch 8/125\n",
      " - 1s - loss: 0.2326 - acc: 0.9354 - val_loss: 0.2206 - val_acc: 0.9399\n",
      "Epoch 9/125\n",
      " - 1s - loss: 0.2218 - acc: 0.9381 - val_loss: 0.2122 - val_acc: 0.9420\n",
      "Epoch 10/125\n",
      " - 1s - loss: 0.2122 - acc: 0.9409 - val_loss: 0.2052 - val_acc: 0.9432\n",
      "Epoch 11/125\n",
      " - 1s - loss: 0.2033 - acc: 0.9437 - val_loss: 0.1989 - val_acc: 0.9454\n",
      "Epoch 12/125\n",
      " - 1s - loss: 0.1955 - acc: 0.9461 - val_loss: 0.1929 - val_acc: 0.9472\n",
      "Epoch 13/125\n",
      " - 1s - loss: 0.1884 - acc: 0.9480 - val_loss: 0.1866 - val_acc: 0.9494\n",
      "Epoch 14/125\n",
      " - 1s - loss: 0.1818 - acc: 0.9497 - val_loss: 0.1820 - val_acc: 0.9507\n",
      "Epoch 15/125\n",
      " - 1s - loss: 0.1755 - acc: 0.9516 - val_loss: 0.1786 - val_acc: 0.9503\n",
      "Epoch 16/125\n",
      " - 1s - loss: 0.1699 - acc: 0.9528 - val_loss: 0.1729 - val_acc: 0.9523\n",
      "Epoch 17/125\n",
      " - 1s - loss: 0.1645 - acc: 0.9544 - val_loss: 0.1689 - val_acc: 0.9538\n",
      "Epoch 18/125\n",
      " - 1s - loss: 0.1593 - acc: 0.9558 - val_loss: 0.1657 - val_acc: 0.9544\n",
      "Epoch 19/125\n",
      " - 1s - loss: 0.1545 - acc: 0.9571 - val_loss: 0.1629 - val_acc: 0.9557\n",
      "Epoch 20/125\n",
      " - 1s - loss: 0.1503 - acc: 0.9584 - val_loss: 0.1580 - val_acc: 0.9576\n",
      "Epoch 21/125\n",
      " - 1s - loss: 0.1458 - acc: 0.9597 - val_loss: 0.1551 - val_acc: 0.9574\n",
      "Epoch 22/125\n",
      " - 1s - loss: 0.1419 - acc: 0.9611 - val_loss: 0.1522 - val_acc: 0.9588\n",
      "Epoch 23/125\n",
      " - 1s - loss: 0.1380 - acc: 0.9627 - val_loss: 0.1492 - val_acc: 0.9595\n",
      "Epoch 24/125\n",
      " - 1s - loss: 0.1344 - acc: 0.9630 - val_loss: 0.1462 - val_acc: 0.9609\n",
      "Epoch 25/125\n",
      " - 1s - loss: 0.1310 - acc: 0.9644 - val_loss: 0.1440 - val_acc: 0.9610\n",
      "Epoch 26/125\n",
      " - 1s - loss: 0.1277 - acc: 0.9653 - val_loss: 0.1428 - val_acc: 0.9616\n",
      "Epoch 27/125\n",
      " - 1s - loss: 0.1244 - acc: 0.9668 - val_loss: 0.1393 - val_acc: 0.9628\n",
      "Epoch 28/125\n",
      " - 1s - loss: 0.1216 - acc: 0.9675 - val_loss: 0.1373 - val_acc: 0.9630\n",
      "Epoch 29/125\n",
      " - 1s - loss: 0.1187 - acc: 0.9684 - val_loss: 0.1356 - val_acc: 0.9638\n",
      "Epoch 30/125\n",
      " - 1s - loss: 0.1159 - acc: 0.9690 - val_loss: 0.1337 - val_acc: 0.9639\n",
      "Epoch 31/125\n",
      " - 1s - loss: 0.1133 - acc: 0.9701 - val_loss: 0.1316 - val_acc: 0.9644\n",
      "Epoch 32/125\n",
      " - 1s - loss: 0.1105 - acc: 0.9707 - val_loss: 0.1302 - val_acc: 0.9648\n",
      "Epoch 33/125\n",
      " - 1s - loss: 0.1080 - acc: 0.9714 - val_loss: 0.1281 - val_acc: 0.9656\n",
      "Epoch 34/125\n",
      " - 1s - loss: 0.1057 - acc: 0.9723 - val_loss: 0.1263 - val_acc: 0.9658\n",
      "Epoch 35/125\n",
      " - 1s - loss: 0.1034 - acc: 0.9727 - val_loss: 0.1253 - val_acc: 0.9661\n",
      "Epoch 36/125\n",
      " - 1s - loss: 0.1014 - acc: 0.9736 - val_loss: 0.1235 - val_acc: 0.9658\n",
      "Epoch 37/125\n",
      " - 1s - loss: 0.0990 - acc: 0.9742 - val_loss: 0.1231 - val_acc: 0.9665\n",
      "Epoch 38/125\n",
      " - 1s - loss: 0.0970 - acc: 0.9747 - val_loss: 0.1211 - val_acc: 0.9668\n",
      "Epoch 39/125\n",
      " - 2s - loss: 0.0951 - acc: 0.9754 - val_loss: 0.1192 - val_acc: 0.9673\n",
      "Epoch 40/125\n",
      " - 2s - loss: 0.0931 - acc: 0.9759 - val_loss: 0.1183 - val_acc: 0.9675\n",
      "Epoch 41/125\n",
      " - 2s - loss: 0.0912 - acc: 0.9762 - val_loss: 0.1165 - val_acc: 0.9681\n",
      "Epoch 42/125\n",
      " - 2s - loss: 0.0895 - acc: 0.9770 - val_loss: 0.1154 - val_acc: 0.9680\n",
      "Epoch 43/125\n",
      " - 2s - loss: 0.0877 - acc: 0.9775 - val_loss: 0.1148 - val_acc: 0.9678\n",
      "Epoch 44/125\n",
      " - 1s - loss: 0.0860 - acc: 0.9780 - val_loss: 0.1134 - val_acc: 0.9688\n",
      "Epoch 45/125\n",
      " - 1s - loss: 0.0843 - acc: 0.9782 - val_loss: 0.1124 - val_acc: 0.9687\n",
      "Epoch 46/125\n",
      " - 1s - loss: 0.0827 - acc: 0.9787 - val_loss: 0.1117 - val_acc: 0.9693\n",
      "Epoch 47/125\n",
      " - 1s - loss: 0.0811 - acc: 0.9794 - val_loss: 0.1110 - val_acc: 0.9688\n",
      "Epoch 48/125\n",
      " - 1s - loss: 0.0797 - acc: 0.9800 - val_loss: 0.1096 - val_acc: 0.9693\n",
      "Epoch 49/125\n",
      " - 1s - loss: 0.0783 - acc: 0.9806 - val_loss: 0.1085 - val_acc: 0.9692\n",
      "Epoch 50/125\n",
      " - 1s - loss: 0.0767 - acc: 0.9811 - val_loss: 0.1077 - val_acc: 0.9701\n",
      "Epoch 51/125\n",
      " - 1s - loss: 0.0754 - acc: 0.9811 - val_loss: 0.1071 - val_acc: 0.9700\n",
      "Epoch 52/125\n",
      " - 1s - loss: 0.0740 - acc: 0.9818 - val_loss: 0.1062 - val_acc: 0.9704\n",
      "Epoch 53/125\n",
      " - 1s - loss: 0.0728 - acc: 0.9822 - val_loss: 0.1054 - val_acc: 0.9708\n",
      "Epoch 54/125\n",
      " - 1s - loss: 0.0714 - acc: 0.9824 - val_loss: 0.1045 - val_acc: 0.9705\n",
      "Epoch 55/125\n",
      " - 1s - loss: 0.0701 - acc: 0.9827 - val_loss: 0.1036 - val_acc: 0.9704\n",
      "Epoch 56/125\n",
      " - 1s - loss: 0.0689 - acc: 0.9832 - val_loss: 0.1035 - val_acc: 0.9706\n",
      "Epoch 57/125\n",
      " - 1s - loss: 0.0677 - acc: 0.9836 - val_loss: 0.1019 - val_acc: 0.9708\n",
      "Epoch 58/125\n",
      " - 1s - loss: 0.0666 - acc: 0.9839 - val_loss: 0.1013 - val_acc: 0.9708\n",
      "Epoch 59/125\n",
      " - 1s - loss: 0.0654 - acc: 0.9842 - val_loss: 0.1009 - val_acc: 0.9704\n",
      "Epoch 60/125\n",
      " - 1s - loss: 0.0644 - acc: 0.9846 - val_loss: 0.1004 - val_acc: 0.9711\n",
      "Epoch 61/125\n",
      " - 1s - loss: 0.0633 - acc: 0.9849 - val_loss: 0.0999 - val_acc: 0.9709\n",
      "Epoch 62/125\n",
      " - 1s - loss: 0.0623 - acc: 0.9854 - val_loss: 0.0987 - val_acc: 0.9712\n",
      "Epoch 63/125\n",
      " - 1s - loss: 0.0612 - acc: 0.9857 - val_loss: 0.0983 - val_acc: 0.9710\n",
      "Epoch 64/125\n",
      " - 1s - loss: 0.0602 - acc: 0.9857 - val_loss: 0.0980 - val_acc: 0.9715\n",
      "Epoch 65/125\n",
      " - 1s - loss: 0.0591 - acc: 0.9862 - val_loss: 0.0979 - val_acc: 0.9717\n",
      "Epoch 66/125\n",
      " - 1s - loss: 0.0584 - acc: 0.9864 - val_loss: 0.0969 - val_acc: 0.9721\n",
      "Epoch 67/125\n",
      " - 1s - loss: 0.0573 - acc: 0.9866 - val_loss: 0.0965 - val_acc: 0.9719\n",
      "Epoch 68/125\n",
      " - 1s - loss: 0.0565 - acc: 0.9871 - val_loss: 0.0962 - val_acc: 0.9715\n",
      "Epoch 69/125\n",
      " - 1s - loss: 0.0556 - acc: 0.9871 - val_loss: 0.0957 - val_acc: 0.9725\n",
      "Epoch 70/125\n",
      " - 1s - loss: 0.0546 - acc: 0.9875 - val_loss: 0.0946 - val_acc: 0.9718\n",
      "Epoch 71/125\n",
      " - 1s - loss: 0.0539 - acc: 0.9876 - val_loss: 0.0941 - val_acc: 0.9725\n",
      "Epoch 72/125\n",
      " - 1s - loss: 0.0530 - acc: 0.9880 - val_loss: 0.0942 - val_acc: 0.9724\n",
      "Epoch 73/125\n",
      " - 2s - loss: 0.0520 - acc: 0.9882 - val_loss: 0.0937 - val_acc: 0.9727\n",
      "Epoch 74/125\n",
      " - 2s - loss: 0.0513 - acc: 0.9886 - val_loss: 0.0929 - val_acc: 0.9729\n",
      "Epoch 75/125\n",
      " - 2s - loss: 0.0506 - acc: 0.9891 - val_loss: 0.0925 - val_acc: 0.9725\n",
      "Epoch 76/125\n",
      " - 1s - loss: 0.0497 - acc: 0.9891 - val_loss: 0.0924 - val_acc: 0.9733\n",
      "Epoch 77/125\n",
      " - 2s - loss: 0.0490 - acc: 0.9891 - val_loss: 0.0918 - val_acc: 0.9735\n",
      "Epoch 78/125\n",
      " - 2s - loss: 0.0482 - acc: 0.9898 - val_loss: 0.0918 - val_acc: 0.9727\n",
      "Epoch 79/125\n",
      " - 2s - loss: 0.0476 - acc: 0.9897 - val_loss: 0.0909 - val_acc: 0.9728\n",
      "Epoch 80/125\n",
      " - 2s - loss: 0.0469 - acc: 0.9900 - val_loss: 0.0904 - val_acc: 0.9731\n",
      "Epoch 81/125\n",
      " - 1s - loss: 0.0462 - acc: 0.9902 - val_loss: 0.0902 - val_acc: 0.9734\n",
      "Epoch 82/125\n",
      " - 2s - loss: 0.0455 - acc: 0.9905 - val_loss: 0.0898 - val_acc: 0.9737\n",
      "Epoch 83/125\n",
      " - 1s - loss: 0.0449 - acc: 0.9906 - val_loss: 0.0891 - val_acc: 0.9738\n",
      "Epoch 84/125\n",
      " - 1s - loss: 0.0441 - acc: 0.9907 - val_loss: 0.0891 - val_acc: 0.9732\n",
      "Epoch 85/125\n",
      " - 1s - loss: 0.0435 - acc: 0.9909 - val_loss: 0.0889 - val_acc: 0.9737\n",
      "Epoch 86/125\n",
      " - 1s - loss: 0.0429 - acc: 0.9912 - val_loss: 0.0883 - val_acc: 0.9737\n",
      "Epoch 87/125\n",
      " - 2s - loss: 0.0423 - acc: 0.9913 - val_loss: 0.0884 - val_acc: 0.9741\n",
      "Epoch 88/125\n",
      " - 2s - loss: 0.0417 - acc: 0.9916 - val_loss: 0.0875 - val_acc: 0.9743\n",
      "Epoch 89/125\n",
      " - 1s - loss: 0.0410 - acc: 0.9919 - val_loss: 0.0879 - val_acc: 0.9738\n",
      "Epoch 90/125\n",
      " - 1s - loss: 0.0405 - acc: 0.9918 - val_loss: 0.0872 - val_acc: 0.9742\n",
      "Epoch 91/125\n",
      " - 1s - loss: 0.0399 - acc: 0.9921 - val_loss: 0.0873 - val_acc: 0.9743\n",
      "Epoch 92/125\n",
      " - 1s - loss: 0.0394 - acc: 0.9921 - val_loss: 0.0870 - val_acc: 0.9742\n",
      "Epoch 93/125\n",
      " - 1s - loss: 0.0388 - acc: 0.9924 - val_loss: 0.0863 - val_acc: 0.9743\n",
      "Epoch 94/125\n",
      " - 1s - loss: 0.0382 - acc: 0.9928 - val_loss: 0.0861 - val_acc: 0.9746\n",
      "Epoch 95/125\n",
      " - 2s - loss: 0.0377 - acc: 0.9929 - val_loss: 0.0864 - val_acc: 0.9747\n",
      "Epoch 96/125\n",
      " - 1s - loss: 0.0372 - acc: 0.9929 - val_loss: 0.0857 - val_acc: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/125\n",
      " - 1s - loss: 0.0367 - acc: 0.9931 - val_loss: 0.0857 - val_acc: 0.9751\n",
      "Epoch 98/125\n",
      " - 1s - loss: 0.0362 - acc: 0.9930 - val_loss: 0.0851 - val_acc: 0.9750\n",
      "Epoch 99/125\n",
      " - 1s - loss: 0.0357 - acc: 0.9932 - val_loss: 0.0850 - val_acc: 0.9753\n",
      "Epoch 100/125\n",
      " - 1s - loss: 0.0352 - acc: 0.9931 - val_loss: 0.0849 - val_acc: 0.9749\n",
      "Epoch 101/125\n",
      " - 2s - loss: 0.0347 - acc: 0.9935 - val_loss: 0.0849 - val_acc: 0.9752\n",
      "Epoch 102/125\n",
      " - 1s - loss: 0.0342 - acc: 0.9938 - val_loss: 0.0849 - val_acc: 0.9752\n",
      "Epoch 103/125\n",
      " - 1s - loss: 0.0338 - acc: 0.9938 - val_loss: 0.0842 - val_acc: 0.9754\n",
      "Epoch 104/125\n",
      " - 1s - loss: 0.0334 - acc: 0.9937 - val_loss: 0.0842 - val_acc: 0.9753\n",
      "Epoch 105/125\n",
      " - 1s - loss: 0.0329 - acc: 0.9940 - val_loss: 0.0837 - val_acc: 0.9759\n",
      "Epoch 106/125\n",
      " - 1s - loss: 0.0324 - acc: 0.9940 - val_loss: 0.0840 - val_acc: 0.9751\n",
      "Epoch 107/125\n",
      " - 2s - loss: 0.0321 - acc: 0.9942 - val_loss: 0.0833 - val_acc: 0.9760\n",
      "Epoch 108/125\n",
      " - 1s - loss: 0.0316 - acc: 0.9944 - val_loss: 0.0830 - val_acc: 0.9763\n",
      "Epoch 109/125\n",
      " - 1s - loss: 0.0312 - acc: 0.9944 - val_loss: 0.0828 - val_acc: 0.9758\n",
      "Epoch 110/125\n",
      " - 1s - loss: 0.0308 - acc: 0.9945 - val_loss: 0.0825 - val_acc: 0.9764\n",
      "Epoch 111/125\n",
      " - 2s - loss: 0.0303 - acc: 0.9947 - val_loss: 0.0826 - val_acc: 0.9758\n",
      "Epoch 112/125\n",
      " - 2s - loss: 0.0300 - acc: 0.9948 - val_loss: 0.0824 - val_acc: 0.9761\n",
      "Epoch 113/125\n",
      " - 2s - loss: 0.0296 - acc: 0.9950 - val_loss: 0.0827 - val_acc: 0.9754\n",
      "Epoch 114/125\n",
      " - 1s - loss: 0.0292 - acc: 0.9948 - val_loss: 0.0820 - val_acc: 0.9763\n",
      "Epoch 115/125\n",
      " - 1s - loss: 0.0288 - acc: 0.9951 - val_loss: 0.0822 - val_acc: 0.9764\n",
      "Epoch 116/125\n",
      " - 1s - loss: 0.0285 - acc: 0.9953 - val_loss: 0.0822 - val_acc: 0.9764\n",
      "Epoch 117/125\n",
      " - 1s - loss: 0.0281 - acc: 0.9954 - val_loss: 0.0819 - val_acc: 0.9769\n",
      "Epoch 118/125\n",
      " - 2s - loss: 0.0277 - acc: 0.9954 - val_loss: 0.0815 - val_acc: 0.9764\n",
      "Epoch 119/125\n",
      " - 2s - loss: 0.0274 - acc: 0.9955 - val_loss: 0.0818 - val_acc: 0.9766\n",
      "Epoch 120/125\n",
      " - 2s - loss: 0.0270 - acc: 0.9956 - val_loss: 0.0813 - val_acc: 0.9760\n",
      "Epoch 121/125\n",
      " - 2s - loss: 0.0267 - acc: 0.9955 - val_loss: 0.0809 - val_acc: 0.9765\n",
      "Epoch 122/125\n",
      " - 1s - loss: 0.0263 - acc: 0.9956 - val_loss: 0.0805 - val_acc: 0.9765\n",
      "Epoch 123/125\n",
      " - 1s - loss: 0.0260 - acc: 0.9958 - val_loss: 0.0808 - val_acc: 0.9764\n",
      "Epoch 124/125\n",
      " - 2s - loss: 0.0257 - acc: 0.9960 - val_loss: 0.0808 - val_acc: 0.9766\n",
      "Epoch 125/125\n",
      " - 1s - loss: 0.0254 - acc: 0.9960 - val_loss: 0.0809 - val_acc: 0.9763\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Обучаем сеть\n",
    "model = Sequential()\n",
    "# Добавляем уровни сети\n",
    "model.add(Dense(1200, input_dim=784, activation=\"relu\", kernel_initializer=\"normal\"))\n",
    "model.add(Dense(1200, activation=\"relu\", kernel_initializer=\"normal\"))\n",
    "model.add(Dense(10, activation=\"softmax\", kernel_initializer=\"normal\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, Y_train, batch_size=200, epochs=125, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

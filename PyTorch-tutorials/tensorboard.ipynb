{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Models, Data, and Training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. TensorBoard setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Writing to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(myenv) euloo@euloo:~/Documents/GitHub/dl/PyTorch-tutorials$ tensorboard --logdir=runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Inspect the model using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Adding a “Projector” to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Tracking model training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Assessing trained models with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

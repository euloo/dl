{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numbers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(train_data)\n",
    "n_pixels = len(train_data.columns) - 1\n",
    "n_class = len(set(train_data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 42000\n",
      "Number of training pixels: 784\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "print('Number of training samples: {0}'.format(n_train))\n",
    "print('Number of training pixels: {0}'.format(n_pixels))\n",
    "print('Number of classes: {0}'.format(n_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('input/test.csv')\n",
    "\n",
    "n_test = len(test_data)\n",
    "n_pixels = len(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 28000\n",
      "Number of test pixels: 784\n"
     ]
    }
   ],
   "source": [
    "print('Number of train samples: {0}'.format(n_test))\n",
    "print('Number of test pixels: {0}'.format(n_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usr\\Anaconda3\\envs\\Py36\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4, 2, 9, 9, 9, 3, 4, 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0QAAAB7CAYAAABU3UDLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAWlUlEQVR4nO3de7TM1f/H8T0OKhxLRW4hrW5C6bisSlhSKqUkyqVjdUELlVwKlXtEKYUllZIukkrJpeiCKCv3a4pakSxxXAoH5XJ+f/zW9917785nmjNnZs7M2c/HX6+P/Zn57OacmTm7ee/3hHJycgwAAAAA+KhIQU8AAAAAAAoKCyIAAAAA3mJBBAAAAMBbLIgAAAAAeIsFEQAAAABvsSACAAAA4K2i4QZDoRA9uQEAAACkvJycnFBu/84nRAAAAAC8xYIIAAAAgLdYEAEAAADwFgsiAAAAAN5iQQQAAADAWyyIAAAAAHiLBREAAAAAb7EgAgAAAOAtFkQAAAAAvMWCCAAAAIC3WBABAAAA8BYLIgAAAADeYkEEAAAAwFssiAAAAAB4iwURAAAAAG+xIAIAAADgLRZEAAAAALzFgggAAACAt1gQAQAAAPBW0YKeAAqHMmXKWMfp6ekR3a5UqVKSO3fubI1lZGQE3q5u3bqSX331VclTpkyxztu4cWNE8wAAJI9q1apZxwMGDJBco0YNySNHjrTOW716teSsrKw4zQ5AYcMnRAAAAAC8xYIIAAAAgLdYEAEAAADwVignJyd4MBQKHoT3unTpIrlPnz7W2AUXXBDRfYRCIcnhfhcjvd1vv/1mnffSSy9JHj16dMT3DwAoOHqfqDHGfPfdd5LDvW/s2LFDst5faowxH330keTNmzfHZJ5IDitWrJB85MgRyb1797bOW7VqVcLmhOSUk5MTyu3f+YQIAAAAgLdYEAEAAADwVkqUzOl2m26LzWnTpknu2LFjzK/dvHlzyZ999pnkuXPnWue1bNky5tdOdtu3b5d87rnnWmORlr/FumQunMzMTOv43Xffjfh6PqhZs6bkRx99VHKbNm2s80qWLCn5m2++scb0ub///nuspwgkVKNGjST37dvXGov0NT/S16pBgwZZxxs2bJA8a9asiK7li65du0q+/fbbrbEbbrhBsvt465/FiBEjJA8cODDWU0SclStXzjpevny55KpVq0p+5ZVXrPO6desW34kVkPr161vHZcuWlazfl91S1MsuuyzwPr/99lvJuiTxySeftM7Lzs7O22QLGCVzAAAAAOBgQQQAAADAWyyIAAAAAHiraEFPIBIlSpSQ7NYEHz58OK7XDmofrfcWGWNMRkaG5NWrV8d1TslC/3e6e4iisWvXLut4+vTpktesWWON6VrwOnXqSG7fvr11XoUKFSS7da++7yGqVauWdTx//nzJFStWDLydfg5effXV1tjatWsl9+rVS7Lvj3V+pKWlSe7Ro4fkxo0bW+fdcccdkt3XyWPHjkl++umnJet9FMYYc+rUqfxNNgWVLl1acocOHayxMWPGSD7jjDOssUj3Li5atEjyOeecY43VqFFD8tChQ62xDz/8UDJ7iGx6X4i7R0TvIdL7j42x94TpMf38MObfzwsEe+KJJyQPHz5csvsYxnqflrsXRu8b0n8fFGb6d3jw4MHWWPHixSWHe60KN6bf36+66irJ119/vXWe3pdVr149a2zs2LGB959s+IQIAAAAgLdYEAEAAADwVkqUzLVt2zZwTJfoxMP555+f678fPXrUOj506FBc55GMdLtT99ug9cewW7dutcbmzJkT03lkZWUFzkPz5WP0cMqUKSP5iy++sMZ0Oc+ePXsku+2GdXvTBQsWWGO6bOGtt97K9d+NMWb06NF5mbZXiha1X5Znz54tWZfqbtq0yTpv8uTJkt0yiCZNmkgeMmSI5PT0dOu8xx57LO8TTkHt2rWTrMt8gl7vc7Nz507Jbkmv/lksXrxYslt2d+aZZ0rWbW1dZ599tmS3RGzVqlWS3a+l8JEu/dXZGGMmTZokuUuXLpJbtWplnUfJXDC33XXnzp0l69cdt1wxFiVzusR06tSp1pi+9pIlSyS/+uqr+b5usmratKnkYsWKBZ63d+9eybpk2hhj9u/fL7l69erWmN4yosuJ9c/BGLss2KX/Pnv77bcDz0sGfEIEAAAAwFssiAAAAAB4K2lL5nTnH7fMQNMfx8WCW56XmZmZ63luRzS3LMw3zz//fEKvp0tI9Efi4TqmDBs2LK5zSgW625vb8Wrfvn2S9e/9559/Hnh/Bw8eDBwrUuSf/9+ycuXKPM3TN7rcwe0opsvknnrqKcluV7JwHeJOO+00yUuXLpXcsWNH6zxdTnHgwIH/mnZS06U9t9xyizWmX6/0e43rt99+k/zee+9ZY6+//rrkH374IaI5uc+X3bt3S9bd0YyxH//x48dLdsu7GjZsKJmSOZtb2qPLvPV7xebNmxM2p1SnS0yNCe7upsvWolWtWjXrWJdmuaV7+uc5bdo0yYW5668uV9Sl1cYYU7t2bclly5aV7G4r6N+/v2S3nK5Zs2aS3Q6ckbryyislUzIHAAAAAEmKBREAAAAAb7EgAgAAAOCtpN1DVKtWLclVqlQJPG/Lli35vtbpp58uWbfiNObfdar/47bdRmLpWtfKlSsHnqd/P6ZPnx7XOSUjXQNsjN1++eTJk9aYbpMdbt9QWlparjmcoOcR/t+LL74o2d1Lomv29R6icHuGXH/99Zdk/Tx45plnrPMqVKggOdX3EOk9P/r33nX8+HHJ7l5Qvac00n1C0fr222+t45tvvlmy3keGyLVu3do61q9Des9Jp06dEjanVKf3YRljP466vXO4r8CIlPv3mN477O4X1vvAZs6cme9rp4Jff/1V8uWXX26N6T3Tjz76qGT37yX9FQHZ2dnW2LZt2yT//fffkosXLx7xHCtVqiRZ72XV70nJgk+IAAAAAHiLBREAAAAAbyVtyVykYtHuWpeNXHfddRHdZsaMGfm+LiL30ksvWcf333+/5HCttnWJkS+KFv3naT127FhrTH/U3aNHD2vs5ZdfzvP964/Aw9GlDrDboBpjl/asW7fOGhsxYoTkEydO5Pva6enpkn/55RdrzD1OJe7vom4769LlomPGjJH85JNPxn5iYeg5jx492hq75557JOufmVsq6bYD951+LumWwsbY7xW+lFXFgi6nDtfu+p133pEcbbvrxo0bS3788ccDr6VbfBtjlz3q0j1fDRo0SLL+mhi3TLpkyZKSP/roI2ts4cKFksO910+ZMkXyV199ZY3p34lkxydEAAAAALzFgggAAACAt1gQAQAAAPBW0u4huvvuu+N234MHD7aOu3XrFtHt/vzzT8mvv/56TOeEf+vZs6fkDh06WGNu/fD/jBs3zjqePXt27CeW5O68807Jun29Mcb89NNPkiPdM+TS7TKPHDkSeJ7ep3Ho0KGorlVYuXX4+tjdL6fbQkdL70G57777JC9btsw679ixY/m+VkHRrxfGGHPWWWcFnrty5UrJidw3pFtpG2NMnz59JIdrDa79+OOP1rH73+0b97mk942WKFHCGtPvG7rdMMK75JJLJIdrdz1y5Mh8X2vAgAGB19LH7n6XeLfFT2X6PWXjxo3W2EMPPST5jjvusMaaNm0qWT/2EydOtM7r1auX5Fjscy0ofEIEAAAAwFssiAAAAAB4K2lL5tLS0mJ6f7oEr1+/flFdS3+T+J49e2IzMQi3ZOSJJ56QrFtDGmN/fLto0SLJbpttH0u1brnllsCxxx57LGHz0O2A33zzzYRdNxUcPXo08Pi8886L+fX08+Wbb76R7La1TWWrVq2yjnX53+mnn26NVahQQbJub/3GG29EfD3d+r9UqVLWWMWKFSU/8sgjkt33miJF+H+S0dBlcvPmzbPGLr74YsnhvpJh6tSpknVpkDF2GZiP6tatax1nZGRIdsvVdelatO2u9ft28+bNA6+l779NmzZRXct3O3bssI5r1qyZ5/s488wzrWP9VRyUzAEAAABACmJBBAAAAMBbSVsyt3btWsm67El3SzLGmGrVqkl2u4xUrlxZ8qRJkyS75ROR2r59e1S3Q7BrrrlG8vvvv2+NhesSpUsWdVe1ffv2xXB2qcntLKfpss9o6c5N7vNR08852LZt22Ydr1ixQnK7du2sMf0t41988YXk2267zTqvbdu2kqdNm2aN9e3bV3L79u3zPuEU8OWXX1rH2dnZkt3XfP2+8corr0gePnx4xNcrX7685FiXeIezZs2ahF0rWS1evFiyLpEzxi6zcjuR6bFWrVpJ3rRpk3XeTTfdJHn+/Pn5m2wKqlGjhnUcrvTw9ttvl3zjjTcGnrdkyZLA+9dlcuGupcf0a2Y4bvnj0qVLA8/VJXkzZ86M6P5Tgd5yMGrUKGtMdxDUHWSNsZ8Xl156qWT3PaR69eqS3fLTv//+O4oZFww+IQIAAADgLRZEAAAAALzFgggAAACAt0Lh6jVDoVDwYALp9piZmZnWmN538vnnn1tjL7zwgmT3G6sjderUKcktWrSQvGDBgqjuD/a3Jnfo0EGy21pbW716tXU8dOhQyXPnzo3h7FKf/t287rrrrLFmzZpJXrhwYVT3P3jw4FyzMcb88ccfknX76IMHD0Z1LV/oNtDr1q2zxsqWLRvRfej9Ebqu3xhjZs2alY/ZpSbdTlt/G7sxxtSpUyeu19avV3pfo9tmWz8fI70/9za+PLf01zAMGzZMsvs3zMcffyy5U6dOgfennyPu1wJkZWVJ9rElt9t2e/ny5ZLdVtj68ddj7s8lmrFIrxWPefTu3Vuy/lsyFenXf/drOfS+odatW1tjn332mWT9fPnggw8Cr/Xss89ax/3798/bZBMgJycnlNu/8wkRAAAAAG+xIAIAAADgrZQomdNlPw8++KA11rJlS8nuR6ia/ib4Tz75xBq76667Am+3cuVKyQ0aNPjvycIYY8xpp50mefz48daY/ob3cB9f65+Z+zOiTC7Yiy++KNktFTp8+LBkXVpijDH79+/P9f6aNGliHV922WWS3eecbtNZu3btCGcMTT93jLEfY/169/DDD1vn6TIXtx36yZMnYznFlFOuXDnr+PLLL5esy7DDtax32/XOnj078Fxd4qafV+7zMVwpji4/7dy5s2S3lbQvPv30U8k33HCDZLc9cps2bfJ837o03hj7vahbt27WmG7TXli5WwwGDBgg2S2r0m3P410yp3/W7jz07X788cdc55eXeeiSOf2emiq6d+8u+bnnnpP866+/WufdeuutkvXjFs71119vHYdrTV+lShXJO3fujOj+442SOQAAAABwsCACAAAA4C0WRAAAAAC8lRJ7iMLR+1F0LaQxxmzfvl2yrgG9+eabrfPC1XFPnDhRsrt/Cf9w9z2MHTtWcteuXQNvp2t2Dx06ZI3de++9kn2tm4+G/lm8/fbb1lirVq0kp6Wlxfzauh3ukCFDYn7/+MeRI0es4x07dkh26+aRHNz3GndPkfbhhx9KvvPOO+M2p1Sh289XrVpV8g8//GCd5z4vIuG2Edavk+PGjbPG9N4SBHP37e3evVtyuL07I0aMkDxw4MA4za7wcb+eQb8fFC9eXLL7d3I0+7Hdvx0mTJgg2f17b+vWrZIzMjIkR/M8jRX2EAEAAACAgwURAAAAAG8VLegJ5Ndrr72Waw5Hf4P5fzlw4EBep+Slhg0bWsfhyuQ03Vpbl8gZQ5lctPQ3T7dt29Ya022FW7RoYY3pltnnnXee5PXr11vnLVy4UHKRIvb/U9FlPog93cLUfezff//9RE8HEdDlQPEoU/XF3r17c82x4LZ31seNGjWK6bV8oVt1G2OXybklc/q9/umnn47vxAqpvn37Wse6dH7JkiWSFyxYkO9ruV/jMHLkSMkdO3a0xi666CLJ1157reQ5c+bkex6xxidEAAAAALzFgggAAACAt1gQAQAAAPBWyu8hioZbu1inTh3JP//8szU2atSohMwpFdWtW1dytPt97rrrLsnh2j926dLFOk5PT5es65GnT59unbdr166o5lVYbdy4MdccznPPPWcd670rv//+uzW2ZcuWfMwO/2XMmDGSixUrZo3prxZA8qhcubLk7t27F+BMEES32Tbm33tcEJkbb7xRcs+ePa0xvS/L3QPWpk2b+E7MA7Vr1w4c0/tLjx8/HvNr6xbfkydPtsYeeeQRyY8//rhk9hABAAAAQBJhQQQAAADAW16WzOnWwy7dBtoYY7Kzs+M9nZSlv0W6dOnS1tipU6ciuo/Zs2dLzkuZgv74Xd9Ot5w2xpiJEydGfJ/IXePGjQPH5s+fbx27jz/y74wzzpDcvHlzyfPmzbPOy8rKSticELkrr7wyqtsNGjQoxjMpnFq3bm0d6xbD4Z4T5cqVk+y2sNfvX24JEILpVtvh3s8zMzMTMR0UAF3WbYxdMpfs+IQIAAAAgLdYEAEAAADwlpclc/v27QscmzFjRgJnktquuOIKyW6JXDRdeqLt7KNvt3r16qjuAzZdhqK7MLrcDnSIvYcffliyLk0dPHhwQUwHEShTpoxk/fMLZ9q0adax2/EUudNlWu5x7969rTFdJqdfu9z3r82bN0v+/vvvYzLPwqpr166SdXm1+5jqEtAFCxbEf2Ke0dsI3ONKlSolbB5333134DzcOSYbPiECAAAA4C0WRAAAAAC8xYIIAAAAgLe83ENUtWrVwDG37TaCTZ8+XXLfvn0Teu1169ZJHjt2rORNmzYldB6FVZUqVSSnpaVZY7t375b8yy+/JGxOvtJ7ULZs2SJ5/fr1BTEdRKB69eqSGzZsGNFt3J9nPL5RvjD6+OOPreOnnnpK8qJFi6wx3V5b73Fx957edNNNkvfu3RuLaRZal1xyiWT9mLp7gkeMGJGwOfmoX79+1nG9evUk9+nTR/LatWut82Kxb/7CCy+UPGzYMGtM/x70798/39eKJz4hAgAAAOAtFkQAAAAAvOVlyZxuvYnozZs3T/K1115rjemW3JHatWuXdaxL8l577TVrbOfOnZIPHTqU52shvFq1agWOTZkyRXJ2dnYipuOVunXrWsfp6emSp06dKvnEiRMJmxPib9KkSQU9hZTklmLp16RWrVpZYzVq1JA8c+ZMyQMHDrTOo0wuco0aNZIcVJKI+NuwYYN1rEvXnn/+ecmjRo2yztNl7ytWrAi8f/13s/6ZG2PM8OHDJRcrVswaW7x4seTly5cH3n8y4BMiAAAAAN5iQQQAAADAWyyIAAAAAHjLyz1Ehw8fLugpFAq6NrR+/foFOBPEmm677Vq2bFkCZ+Kfhx56yDouWbKk5HHjxiV6OkBKeeGFF3LNiI/NmzdLzsjIkKz3aCHxJkyYILl27dqS7733Xuu8pUuXSnbbz4dCIcn662rKly9vnaf3i40ZM8Yac9uBJzM+IQIAAADgLRZEAAAAALzlZclc+/btreN33nmngGYCJI+iRf95OXDbaiJx3Mf+66+/lrx79+5ETwcAAnXq1CnXjOTxwAMPSHbbc2dmZkpu0KCBNaZL5rKysiS7fzPPmTNH8owZM/I32QLEJ0QAAAAAvMWCCAAAAIC3Qjk5OcGDoVDwIAAgJurUqSN55cqV1livXr0kjx8/PmFzAgCgsMnJyQnl9u98QgQAAADAWyyIAAAAAHiLBREAAAAAb7GHCAAAAEChxx4iAAAAAHCwIAIAAADgLRZEAAAAALzFgggAAACAt1gQAQAAAPAWCyIAAAAA3mJBBAAAAMBbLIgAAAAAeIsFEQAAAABvhXJycgp6DgAAAABQIPiECAAAAIC3WBABAAAA8BYLIgAAAADeYkEEAAAAwFssiAAAAAB4iwURAAAAAG/9Hzg52hDHC0ynAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_sel = np.random.randint(n_train, size=8)\n",
    "\n",
    "grid = make_grid(torch.Tensor((train_data.iloc[random_sel, 1:].as_matrix()/255.).reshape((-1, 28, 28))).unsqueeze(1), nrow=8)\n",
    "plt.rcParams['figure.figsize'] = (16, 2)\n",
    "plt.imshow(grid.numpy().transpose((1,2,0)))\n",
    "plt.axis('off')\n",
    "print(*list(train_data.iloc[random_sel, 0].values), sep = ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "plt.bar(train_data['label'].value_counts().index, train_data['label'].value_counts())\n",
    "plt.xticks(np.arange(n_class))\n",
    "plt.xlabel('Class', fontsize=16)\n",
    "plt.ylabel('Count', fontsize=16)\n",
    "plt.grid('on', axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num, px = np.array(train_data).shape\n",
    "height = width = int(np.sqrt(px-1))\n",
    "num, px, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_min = np.array(train_data).min()\n",
    "img_max = np.array(train_data).max()\n",
    "img_min, img_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13087070313475707"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_norm_mean = np.array(train_data, dtype=float).mean() / img_max\n",
    "img_norm_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3085670315794816"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_std = np.sqrt(np.sum((np.array(train_data) / img_max  - img_norm_mean) ** 2) / (num * height * width))\n",
    "img_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_data(Dataset):\n",
    "    \"\"\"MNIST dtaa set\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, \n",
    "                 transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n",
    "                     transforms.Normalize(mean=(img_norm_mean,), std=(img_std,))])\n",
    "                ):\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if len(df.columns) == n_pixels:\n",
    "            # test data\n",
    "            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = None\n",
    "        else:\n",
    "            # training data\n",
    "            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = torch.from_numpy(df.iloc[:,0].values)\n",
    "            \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        else:\n",
    "            return self.transform(self.X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_data('input/train.csv', transform= transforms.Compose(\n",
    "                            [transforms.ToPILImage(),\n",
    "                             transforms.ToTensor(), \n",
    "                             transforms.Normalize(mean=(img_norm_mean,), std=(img_std,))]))\n",
    "\n",
    "test_dataset = MNIST_data('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, \n",
    "                               out_channels=4, \n",
    "                               kernel_size=5,\n",
    "                               padding=0)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=4, \n",
    "                               out_channels=8, \n",
    "                               kernel_size=3, \n",
    "                               padding=0)\n",
    "        \n",
    "        #fully connected layers\n",
    "        ## convert matrix with 8*5*5 (= 200) features to a matrix of 120 features (columns)\n",
    "        self.fc1 = nn.Linear(in_features=8*5*5,\n",
    "                             out_features=120) \n",
    "        self.fc2 = nn.Linear(in_features=120, \n",
    "                             out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, \n",
    "                             out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # convolve, then perform ReLU non-linearity\n",
    "        # max-pooling with 2x2 grid \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        \n",
    "        # flattening convolutional layer\n",
    "        x = x.view(-1, 8 * 5 * 5)\n",
    "        \n",
    "        # fully-connected layers + perform ReLU non-linearity\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "    def features_2(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "    \n",
    "    def features_1(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=200, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LeNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x282b8c0ddf0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "log_interval = 1000\n",
    "iterations = len(train_loader.dataset)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size                 42000\n",
      "validation set size               28000\n",
      "batch size (training/validation)  8\n",
      "iterations in epoch               5250\n"
     ]
    }
   ],
   "source": [
    "print(\"training set size                \", len(train_loader.dataset))\n",
    "print(\"validation set size              \", len(test_loader.dataset))\n",
    "print(\"batch size (training/validation) \", batch_size)\n",
    "print(\"iterations in epoch              \", iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch  1 ===\n",
      "Epoch 1, step  1000 loss: 2.292\n",
      "Epoch 1, step  2000 loss: 2.255\n",
      "Epoch 1, step  3000 loss: 2.068\n",
      "Epoch 1, step  4000 loss: 1.111\n",
      "Epoch 1, step  5000 loss: 0.631\n",
      "=== epoch  2 ===\n",
      "Epoch 2, step  1000 loss: 0.480\n",
      "Epoch 2, step  2000 loss: 0.423\n",
      "Epoch 2, step  3000 loss: 0.375\n",
      "Epoch 2, step  4000 loss: 0.353\n",
      "Epoch 2, step  5000 loss: 0.325\n",
      "=== epoch  3 ===\n",
      "Epoch 3, step  1000 loss: 0.291\n",
      "Epoch 3, step  2000 loss: 0.279\n",
      "Epoch 3, step  3000 loss: 0.255\n",
      "Epoch 3, step  4000 loss: 0.250\n",
      "Epoch 3, step  5000 loss: 0.222\n",
      "=== epoch  4 ===\n",
      "Epoch 4, step  1000 loss: 0.208\n",
      "Epoch 4, step  2000 loss: 0.202\n",
      "Epoch 4, step  3000 loss: 0.186\n",
      "Epoch 4, step  4000 loss: 0.181\n",
      "Epoch 4, step  5000 loss: 0.184\n",
      "=== epoch  5 ===\n",
      "Epoch 5, step  1000 loss: 0.165\n",
      "Epoch 5, step  2000 loss: 0.149\n",
      "Epoch 5, step  3000 loss: 0.162\n",
      "Epoch 5, step  4000 loss: 0.154\n",
      "Epoch 5, step  5000 loss: 0.140\n",
      "=== epoch  6 ===\n",
      "Epoch 6, step  1000 loss: 0.134\n",
      "Epoch 6, step  2000 loss: 0.125\n",
      "Epoch 6, step  3000 loss: 0.131\n",
      "Epoch 6, step  4000 loss: 0.137\n",
      "Epoch 6, step  5000 loss: 0.124\n",
      "=== epoch  7 ===\n",
      "Epoch 7, step  1000 loss: 0.124\n",
      "Epoch 7, step  2000 loss: 0.118\n",
      "Epoch 7, step  3000 loss: 0.115\n",
      "Epoch 7, step  4000 loss: 0.115\n",
      "Epoch 7, step  5000 loss: 0.105\n",
      "=== epoch  8 ===\n",
      "Epoch 8, step  1000 loss: 0.110\n",
      "Epoch 8, step  2000 loss: 0.105\n",
      "Epoch 8, step  3000 loss: 0.099\n",
      "Epoch 8, step  4000 loss: 0.104\n",
      "Epoch 8, step  5000 loss: 0.092\n",
      "=== epoch  9 ===\n",
      "Epoch 9, step  1000 loss: 0.097\n",
      "Epoch 9, step  2000 loss: 0.105\n",
      "Epoch 9, step  3000 loss: 0.085\n",
      "Epoch 9, step  4000 loss: 0.091\n",
      "Epoch 9, step  5000 loss: 0.092\n",
      "=== epoch 10 ===\n",
      "Epoch 10, step  1000 loss: 0.091\n",
      "Epoch 10, step  2000 loss: 0.086\n",
      "Epoch 10, step  3000 loss: 0.079\n",
      "Epoch 10, step  4000 loss: 0.081\n",
      "Epoch 10, step  5000 loss: 0.083\n",
      "=== epoch 11 ===\n",
      "Epoch 11, step  1000 loss: 0.078\n",
      "Epoch 11, step  2000 loss: 0.080\n",
      "Epoch 11, step  3000 loss: 0.081\n",
      "Epoch 11, step  4000 loss: 0.084\n",
      "Epoch 11, step  5000 loss: 0.071\n",
      "=== epoch 12 ===\n",
      "Epoch 12, step  1000 loss: 0.071\n",
      "Epoch 12, step  2000 loss: 0.072\n",
      "Epoch 12, step  3000 loss: 0.080\n",
      "Epoch 12, step  4000 loss: 0.074\n",
      "Epoch 12, step  5000 loss: 0.075\n",
      "=== epoch 13 ===\n",
      "Epoch 13, step  1000 loss: 0.069\n",
      "Epoch 13, step  2000 loss: 0.075\n",
      "Epoch 13, step  3000 loss: 0.072\n",
      "Epoch 13, step  4000 loss: 0.062\n",
      "Epoch 13, step  5000 loss: 0.067\n",
      "=== epoch 14 ===\n",
      "Epoch 14, step  1000 loss: 0.068\n",
      "Epoch 14, step  2000 loss: 0.061\n",
      "Epoch 14, step  3000 loss: 0.065\n",
      "Epoch 14, step  4000 loss: 0.062\n",
      "Epoch 14, step  5000 loss: 0.066\n",
      "=== epoch 15 ===\n",
      "Epoch 15, step  1000 loss: 0.059\n",
      "Epoch 15, step  2000 loss: 0.065\n",
      "Epoch 15, step  3000 loss: 0.061\n",
      "Epoch 15, step  4000 loss: 0.066\n",
      "Epoch 15, step  5000 loss: 0.061\n",
      "=== epoch 16 ===\n",
      "Epoch 16, step  1000 loss: 0.051\n",
      "Epoch 16, step  2000 loss: 0.057\n",
      "Epoch 16, step  3000 loss: 0.064\n",
      "Epoch 16, step  4000 loss: 0.061\n",
      "Epoch 16, step  5000 loss: 0.056\n",
      "=== epoch 17 ===\n",
      "Epoch 17, step  1000 loss: 0.056\n",
      "Epoch 17, step  2000 loss: 0.065\n",
      "Epoch 17, step  3000 loss: 0.051\n",
      "Epoch 17, step  4000 loss: 0.055\n",
      "Epoch 17, step  5000 loss: 0.056\n",
      "=== epoch 18 ===\n",
      "Epoch 18, step  1000 loss: 0.056\n",
      "Epoch 18, step  2000 loss: 0.053\n",
      "Epoch 18, step  3000 loss: 0.052\n",
      "Epoch 18, step  4000 loss: 0.058\n",
      "Epoch 18, step  5000 loss: 0.051\n",
      "=== epoch 19 ===\n",
      "Epoch 19, step  1000 loss: 0.050\n",
      "Epoch 19, step  2000 loss: 0.058\n",
      "Epoch 19, step  3000 loss: 0.048\n",
      "Epoch 19, step  4000 loss: 0.047\n",
      "Epoch 19, step  5000 loss: 0.057\n",
      "=== epoch 20 ===\n",
      "Epoch 20, step  1000 loss: 0.043\n",
      "Epoch 20, step  2000 loss: 0.055\n",
      "Epoch 20, step  3000 loss: 0.043\n",
      "Epoch 20, step  4000 loss: 0.057\n",
      "Epoch 20, step  5000 loss: 0.052\n",
      "Wall time: 12min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(epochs): # entire dataset is passed forward and backward through the nn\n",
    "    model.train()\n",
    "    \n",
    "    epoch_training_loss = 0\n",
    "    print(\"=== epoch %2d ===\" % (epoch + 1))\n",
    "    \n",
    "    for batch_idx, training_batch in enumerate(train_loader, 0):        \n",
    "        inputs, labels = training_batch[0].to(device), training_batch[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward propagation\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        #backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters(weight,bias)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_training_loss += loss.item()# .data\n",
    "        if batch_idx % 1000 == 999:    \n",
    "            print('Epoch %d, step %5d loss: %.3f' %\n",
    "                  (epoch + 1, batch_idx + 1, epoch_training_loss / 1000))\n",
    "            epoch_training_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_pred = torch.LongTensor()\n",
    "test_pred = test_pred.to(device)\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        test_pred = torch.cat((test_pred, pred), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [0],\n",
       "        [9],\n",
       "        ...,\n",
       "        [3],\n",
       "        [9],\n",
       "        [2]], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.cpu().numpy()], \n",
    "                      columns=['ImageId', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      9\n",
       "4        5      3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('submission_LeNet5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![wtf](images\\submissions.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Py36] *",
   "language": "python",
   "name": "conda-env-Py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

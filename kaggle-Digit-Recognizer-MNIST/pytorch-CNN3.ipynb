{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numbers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(train_data)\n",
    "n_pixels = len(train_data.columns) - 1\n",
    "n_class = len(set(train_data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 42000\n",
      "Number of training pixels: 784\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "print('Number of training samples: {0}'.format(n_train))\n",
    "print('Number of training pixels: {0}'.format(n_pixels))\n",
    "print('Number of classes: {0}'.format(n_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('input/test.csv')\n",
    "\n",
    "n_test = len(test_data)\n",
    "n_pixels = len(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 28000\n",
      "Number of test pixels: 784\n"
     ]
    }
   ],
   "source": [
    "print('Number of train samples: {0}'.format(n_test))\n",
    "print('Number of test pixels: {0}'.format(n_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usr\\Anaconda3\\envs\\Py36\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5, 3, 3, 7, 8, 5, 8, 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_sel = np.random.randint(n_train, size=8)\n",
    "\n",
    "grid = make_grid(torch.Tensor((train_data.iloc[random_sel, 1:].as_matrix()/255.).reshape((-1, 28, 28))).unsqueeze(1), nrow=8)\n",
    "plt.rcParams['figure.figsize'] = (16, 2)\n",
    "plt.imshow(grid.numpy().transpose((1,2,0)))\n",
    "plt.axis('off')\n",
    "print(*list(train_data.iloc[random_sel, 0].values), sep = ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "plt.bar(train_data['label'].value_counts().index, train_data['label'].value_counts())\n",
    "plt.xticks(np.arange(n_class))\n",
    "plt.xlabel('Class', fontsize=16)\n",
    "plt.ylabel('Count', fontsize=16)\n",
    "plt.grid('on', axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num, px = np.array(train_data).shape\n",
    "height = width = int(np.sqrt(px-1))\n",
    "num, px, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_min = np.array(train_data).min()\n",
    "img_max = np.array(train_data).max()\n",
    "img_min, img_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13087070313475707"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_norm_mean = np.array(train_data, dtype=float).mean() / img_max\n",
    "img_norm_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3085670315794816"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_std = np.sqrt(np.sum((np.array(train_data) / img_max  - img_norm_mean) ** 2) / (num * height * width))\n",
    "img_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_data(Dataset):\n",
    "    \"\"\"MNIST dtaa set\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, \n",
    "                 transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n",
    "                     transforms.Normalize(mean=(img_norm_mean,), std=(img_std,))])\n",
    "                ):\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if len(df.columns) == n_pixels:\n",
    "            # test data\n",
    "            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = None\n",
    "        else:\n",
    "            # training data\n",
    "            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = torch.from_numpy(df.iloc[:,0].values)\n",
    "            \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        else:\n",
    "            return self.transform(self.X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_data('input/train.csv', transform= transforms.Compose(\n",
    "                            [transforms.ToPILImage(),\n",
    "                             transforms.ToTensor(), \n",
    "                             transforms.Normalize(mean=(img_norm_mean,), std=(img_std,))]))\n",
    "\n",
    "test_dataset = MNIST_data('input/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, \n",
    "                               out_channels=3, \n",
    "                               kernel_size=5, \n",
    "                               padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, \n",
    "                               out_channels=5, \n",
    "                               kernel_size=3, \n",
    "                               padding=0)\n",
    "        self.fc1 = nn.Linear(5 * 22 * 22, 128) \n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 5 * 22 * 22)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=2420, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21fcee09e70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "log_interval = 1000\n",
    "iterations = len(train_loader.dataset)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size                 42000\n",
      "validation set size               28000\n",
      "batch size (training/validation)  8\n",
      "iterations in epoch               5250\n"
     ]
    }
   ],
   "source": [
    "print(\"training set size                \", len(train_loader.dataset))\n",
    "print(\"validation set size              \", len(test_loader.dataset))\n",
    "print(\"batch size (training/validation) \", batch_size)\n",
    "print(\"iterations in epoch              \", iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch  1 ===\n",
      "Epoch 1, step  1000 loss: 1.632\n",
      "Epoch 1, step  2000 loss: 0.450\n",
      "Epoch 1, step  3000 loss: 0.359\n",
      "Epoch 1, step  4000 loss: 0.308\n",
      "Epoch 1, step  5000 loss: 0.287\n",
      "=== epoch  2 ===\n",
      "Epoch 2, step  1000 loss: 0.234\n",
      "Epoch 2, step  2000 loss: 0.228\n",
      "Epoch 2, step  3000 loss: 0.207\n",
      "Epoch 2, step  4000 loss: 0.191\n",
      "Epoch 2, step  5000 loss: 0.185\n",
      "=== epoch  3 ===\n",
      "Epoch 3, step  1000 loss: 0.165\n",
      "Epoch 3, step  2000 loss: 0.169\n",
      "Epoch 3, step  3000 loss: 0.148\n",
      "Epoch 3, step  4000 loss: 0.152\n",
      "Epoch 3, step  5000 loss: 0.135\n",
      "=== epoch  4 ===\n",
      "Epoch 4, step  1000 loss: 0.128\n",
      "Epoch 4, step  2000 loss: 0.129\n",
      "Epoch 4, step  3000 loss: 0.123\n",
      "Epoch 4, step  4000 loss: 0.119\n",
      "Epoch 4, step  5000 loss: 0.123\n",
      "=== epoch  5 ===\n",
      "Epoch 5, step  1000 loss: 0.108\n",
      "Epoch 5, step  2000 loss: 0.097\n",
      "Epoch 5, step  3000 loss: 0.106\n",
      "Epoch 5, step  4000 loss: 0.109\n",
      "Epoch 5, step  5000 loss: 0.102\n",
      "=== epoch  6 ===\n",
      "Epoch 6, step  1000 loss: 0.091\n",
      "Epoch 6, step  2000 loss: 0.088\n",
      "Epoch 6, step  3000 loss: 0.088\n",
      "Epoch 6, step  4000 loss: 0.100\n",
      "Epoch 6, step  5000 loss: 0.091\n",
      "=== epoch  7 ===\n",
      "Epoch 7, step  1000 loss: 0.081\n",
      "Epoch 7, step  2000 loss: 0.084\n",
      "Epoch 7, step  3000 loss: 0.086\n",
      "Epoch 7, step  4000 loss: 0.081\n",
      "Epoch 7, step  5000 loss: 0.077\n",
      "=== epoch  8 ===\n",
      "Epoch 8, step  1000 loss: 0.074\n",
      "Epoch 8, step  2000 loss: 0.072\n",
      "Epoch 8, step  3000 loss: 0.070\n",
      "Epoch 8, step  4000 loss: 0.068\n",
      "Epoch 8, step  5000 loss: 0.070\n",
      "=== epoch  9 ===\n",
      "Epoch 9, step  1000 loss: 0.066\n",
      "Epoch 9, step  2000 loss: 0.070\n",
      "Epoch 9, step  3000 loss: 0.059\n",
      "Epoch 9, step  4000 loss: 0.065\n",
      "Epoch 9, step  5000 loss: 0.062\n",
      "=== epoch 10 ===\n",
      "Epoch 10, step  1000 loss: 0.058\n",
      "Epoch 10, step  2000 loss: 0.063\n",
      "Epoch 10, step  3000 loss: 0.053\n",
      "Epoch 10, step  4000 loss: 0.052\n",
      "Epoch 10, step  5000 loss: 0.058\n",
      "Wall time: 4min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(epochs): # entire dataset is passed forward and backward through the nn\n",
    "    model.train()\n",
    "    \n",
    "    epoch_training_loss = 0\n",
    "    print(\"=== epoch %2d ===\" % (epoch + 1))\n",
    "    \n",
    "    for batch_idx, training_batch in enumerate(train_loader, 0):        \n",
    "        inputs, labels = training_batch[0].to(device), training_batch[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward propagation\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        #backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters(weight,bias)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_training_loss += loss.item()# .data\n",
    "        if batch_idx % 1000 == 999:    \n",
    "            print('Epoch %d, step %5d loss: %.3f' %\n",
    "                  (epoch + 1, batch_idx + 1, epoch_training_loss / 1000))\n",
    "            epoch_training_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_pred = torch.LongTensor()\n",
    "test_pred = test_pred.to(device)\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        test_pred = torch.cat((test_pred, pred), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [0],\n",
       "        [9],\n",
       "        ...,\n",
       "        [3],\n",
       "        [9],\n",
       "        [2]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.cpu().numpy()], \n",
    "                      columns=['ImageId', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      9\n",
       "4        5      3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('submission_CNN3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
